{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 22:32:53,776 - __main__ - INFO - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Current working directory: c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\n",
      "2024-12-15 22:32:53,776 - __main__ - INFO - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Current working directory: c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\n",
      "2024-12-15 22:32:53,776 - __main__ - INFO - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Current working directory: c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\n",
      "2024-12-15 22:32:53,776 - __main__ - INFO - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Current working directory: c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\n",
      "2024-12-15 22:32:53,776 - __main__ - INFO - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Current working directory: c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\n",
      "2024-12-15 22:32:53,781 - utils.explorefigs - INFO - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Saving figures to C:/Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\Figures\\Images\n",
      "2024-12-15 22:32:53,932 - loaddata.session_info - INFO - c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\\loaddata\\session_info.py - ['IM'] dataset: 1 mice, 1 sessions, 5600 trials\n",
      "2024-12-15 22:32:53,942 - loaddata.session_info - INFO - c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\\loaddata\\session_info.py - Number of neurons in PM: 1173\n",
      "2024-12-15 22:32:53,944 - loaddata.session_info - INFO - c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\\loaddata\\session_info.py - Number of neurons in V1: 2769\n",
      "2024-12-15 22:32:53,945 - loaddata.session_info - INFO - c:\\Users\\asimo\\Documents\\BCCN\\Lab Rotations\\Petreanu Lab\\molanalysis\\loaddata\\session_info.py - Total number of neurons: 3942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a054fd227db24596aff46a6299adc29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de57f1b33bc442428b3aa54ced6bbaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for response matrix:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad12747c71641b2bf5e04eeafceff59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for runspeed:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07212d63a97433fbbcb59df24973fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for motion energy:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629f89fdcb964b5491d7e4e10e380014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for pupil x position:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e3851393c64d8797fca4b881232804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for pupil y position:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3de946f98874907b8a399a7679d5c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing average response for pupil area:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 22:33:38,505 - utils.explorefigs - WARNING - C:\\Users\\asimo\\AppData\\Local\\Temp\\ipykernel_3536\\3599183259.py - Removing sessions idx = [] from sessions lists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94972aafa3644ea5b0f6385f48906b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trials for LPE10885/2023_10_20: 5600\n",
      "num_trials for LPE10885/2023_10_20: 5600\n",
      "num_neurons for LPE10885/2023_10_20: 1173\n",
      "num_neurons for LPE10885/2023_10_20: 1173\n",
      "num_trials for LPE10885/2023_10_20: 5600\n"
     ]
    }
   ],
   "source": [
    "# If you want to save a subset of the data, define these manually here. All three variables have to be defined. Else, leave this blank\n",
    "\n",
    "import os \n",
    "# session_list = np.array([['LPE10885', '2023_10_20']])\n",
    "# session_list = np.array(session_list)\n",
    "# folders = [os.path.join(INPUT_FOLDER, 'LPE10885')]\n",
    "# files = [[folder, os.path.join(folder, '2023_10_20')]\n",
    "#          for folder in folders]\n",
    "\n",
    "# Imports\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This script analyzes neural and behavioral data in a multi-area calcium imaging\n",
    "dataset with labeled projection neurons. The visual stimuli are natural images.\n",
    "Matthijs Oude Lohuis, 2023, Champalimaud Center\n",
    "Anastasia Simonoff, 2024, Bernstein Center for Computational Neuroscience Berlin\n",
    "\"\"\"\n",
    "\n",
    "# Import general libs\n",
    "import logging\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "\n",
    "# Set working directory to root of repo\n",
    "current_path = os.getcwd()\n",
    "# Identify if path has 'molanalysis' as a folder in it\n",
    "if 'molanalysis' in current_path:\n",
    "    # If so, set the path to the root of the repo\n",
    "    current_path = current_path.split('molanalysis')[0] + 'molanalysis'\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f'This needs to be run somewhere from within the molanalysis folder, not {current_path}')\n",
    "os.chdir(current_path)\n",
    "sys.path.append(current_path)\n",
    "\n",
    "from sensorium_utility_training_read_config import read_config\n",
    "\n",
    "run_config = read_config('../Petreanu_MEI_generation/run_config.yaml') # Must be set\n",
    "\n",
    "RUN_NAME = run_config['RUN_NAME'] # MUST be set. Creates a subfolder in the runs folder with this name, containing data, saved models, etc. IMPORTANT: all values in this folder WILL be deleted.\n",
    "\n",
    "keep_behavioral_info = run_config['data']['keep_behavioral_info']\n",
    "area_of_interest = run_config['data']['area_of_interest']\n",
    "sessions_to_keep = run_config['data']['sessions_to_keep']\n",
    "OUTPUT_NAME = run_config['data']['OUTPUT_NAME']\n",
    "INPUT_FOLDER = run_config['data']['INPUT_FOLDER']\n",
    "OUTPUT_FOLDER = f'../molanalysis/MEI_generation/data/{OUTPUT_NAME}' # relative to molanalysis root folder\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(pathname)s - %(message)s', handlers=[logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# Create a StreamHandler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)  # Set the logging level for the handler\n",
    "# Create a Formatter and attach it to the handler\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(pathname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "logger.info('Current working directory: %s', os.getcwd())\n",
    "\n",
    "# TODO: Fix this so it outputs correctly during figure generation\n",
    "rmap_logger = logging.getLogger('rastermap')\n",
    "rmap_logger.setLevel(logging.WARNING)\n",
    "rmap_logger.addHandler(console_handler)\n",
    "rmap_logger.propagate = False\n",
    "\n",
    "# Import personal lib funcs\n",
    "from loaddata.session_info import load_sessions\n",
    "from utils.imagelib import load_natural_images\n",
    "from utils.explorefigs import *\n",
    "from loaddata.get_data_folder import get_local_drive\n",
    "\n",
    "\n",
    "# Updated by Anastasia Simonoff for her local computer, etc. This should be updated for your local computer, too.\n",
    "\n",
    "savedir = os.path.join(get_local_drive(\n",
    "), 'Users\\\\asimo\\\\Documents\\\\BCCN\\\\Lab Rotations\\\\Petreanu Lab\\\\Figures\\\\Images' if os.environ['USERDOMAIN'] == 'ULTINTELLIGENCE' else 'OneDrive\\\\PostDoc\\\\Figures\\\\Images\\\\')\n",
    "logger.info(f'Saving figures to {savedir}')\n",
    "\n",
    "# INPUT_FOLDER = \"../sensorium/notebooks/data/IM_prezipped\"\n",
    "# Add Add folders two levels deep from INPUT_FOLDER into a list\n",
    "\n",
    "# Delete anything in OUTPUT_FOLDER\n",
    "# import shutil\n",
    "# try:\n",
    "#     shutil.rmtree(OUTPUT_FOLDER)\n",
    "# except FileNotFoundError:\n",
    "#     os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# test if folders already defined \n",
    "try: \n",
    "    folders\n",
    "except NameError:\n",
    "    # First level\n",
    "    folders = [os.path.join(INPUT_FOLDER, name) for name in os.listdir(\n",
    "        INPUT_FOLDER) if os.path.isdir(os.path.join(INPUT_FOLDER, name)) and not \"merged_data\" in name]\n",
    "    folders = [x.replace(\"\\\\\", \"/\") for x in folders]\n",
    "    # Second level\n",
    "    files = [[folder, os.path.join(folder, name).replace('\\\\', '/')] for folder in folders for name in os.listdir(\n",
    "        folder) if os.path.isdir(os.path.join(folder, name)) and not \"merged_data\" in name]\n",
    "    # only get last value after /\n",
    "    session_list = [[folder.split(\"/\")[-1], name.split(\"/\")[-1]]\n",
    "                    for folder, name in files]\n",
    "\n",
    "    # drop ['LPE10919', '2023_11_08'] because the data is not converted yet\n",
    "    session_list = [x for x in session_list if x != ['LPE10919', '2023_11_08']]\n",
    "    print(session_list)\n",
    "\n",
    "if sessions_to_keep != 'all':\n",
    "    session_list = [x for x in session_list if x in np.array(sessions_to_keep)]\n",
    "\n",
    "# Load one session including raw data: ################################################\n",
    "# example session with good responses\n",
    "\n",
    "# Load sessions lazy: (no calciumdata, behaviordata etc.,)\n",
    "sessions, nSessions = load_sessions(protocol='IM', session_list=np.array(session_list), data_folder=INPUT_FOLDER)\n",
    "\n",
    "# Load proper data and compute average trial responses:\n",
    "for ises in tqdm(range(nSessions)):    # iterate over sessions\n",
    "\n",
    "    # os.makedirs(os.path.join(OUTPUT_FOLDER, session_list[ises][0], session_list[ises][1], 'data'), exist_ok=True)\n",
    "\n",
    "    sessions[ises].load_respmat(calciumversion='deconv', keepraw=True)\n",
    "\n",
    "    # Save respmat\n",
    "    # # np.save(os.path.join(files[ises][1], 'respmat.npy'), sessions[ises].respmat)\n",
    "    # np.save(os.path.join(OUTPUT_FOLDER, session_list[ises][0], session_list[ises][1], 'data', 'respmat.npy'), sessions[ises].respmat)\n",
    "\n",
    "# Load all IM sessions including raw data: ################################################\n",
    "# sessions,nSessions   = filter_sessions(protocols = ['IM'])\n",
    "# for ises in range(nSessions):    # iterate over sessions\n",
    "#     sessions[ises].load_respmat(calciumversion='deconv',keepraw=False)\n",
    "\n",
    "def replace_nan_with_avg(arr):\n",
    "    arr = arr.copy()  # Copy the array to avoid modifying the original\n",
    "    nan_indices = np.where(np.isnan(arr))[0]  # Get indices of NaN values\n",
    "\n",
    "    for i in nan_indices:\n",
    "        # Handle cases where NaN is at the start or end of the array\n",
    "        if i == 0:\n",
    "            arr[i] = arr[i + 1]\n",
    "        elif i == len(arr) - 1:\n",
    "            arr[i] = arr[i - 1]\n",
    "        else:\n",
    "            # Replace NaN with the average of adjacent values\n",
    "            arr[i] = np.nanmean([arr[i - 1], arr[i + 1]])\n",
    "\n",
    "    return arr\n",
    "\n",
    "import shutil \n",
    "# Save behavior data in sensorium format\n",
    "\n",
    "idx_to_delete = []\n",
    "\n",
    "for i, (sess, sess_obj) in enumerate(zip(session_list, sessions)):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    pupil_size = sess_obj.respmat_pupilarea.reshape(-1, 1)\n",
    "    change_of_pupil_size = sess_obj.respmat_pupilareaderiv.reshape(-1, 1)\n",
    "    locotomion_speed = sess_obj.respmat_runspeed.reshape(-1, 1)\n",
    "\n",
    "    # Data\n",
    "    folder = f'{folder_base}/data/behavior'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # if np.isnan(pupil_size).all() or np.isnan(change_of_pupil_size).all() or np.isnan(locotomion_speed).all():\n",
    "    #     logger.warning(\n",
    "    #         f'All values in behavior data for session {sess[0]}/{sess[1]} are NaN. Session will be removed.')\n",
    "    #     # Drop session from list\n",
    "    #     # session_list = np.delete(session_list, i, axis=0)\n",
    "    #     # sessions = np.delete(sessions, i, axis=0)\n",
    "    #     idx_to_delete.append(i)\n",
    "    #     # Remove folder\n",
    "    #     shutil.rmtree(folder_base)\n",
    "    #     try:\n",
    "    #         os.rmdir(folder_base)\n",
    "    #     except FileNotFoundError:\n",
    "    #         pass\n",
    "    #     try:\n",
    "    #         shutil.rmtree(f'../sensorium/notebooks/data/IM_prezipped/{sess[0]}/{sess[1]}/')\n",
    "    #         if len(os.listdir(f'../sensorium/notebooks/data/IM_prezipped/{sess[0]}')) == 0:\n",
    "    #             os.rmdir(f'../sensorium/notebooks/data/IM_prezipped/{sess[0]}/')\n",
    "    #     except FileNotFoundError:\n",
    "    #         pass\n",
    "    #     continue\n",
    "\n",
    "    behavior = np.hstack((pupil_size, change_of_pupil_size, locotomion_speed))\n",
    "    if keep_behavioral_info:\n",
    "        behavior = replace_nan_with_avg(behavior)\n",
    "        assert not np.isnan(behavior).any(), 'There are still NaN values in the behavior data'\n",
    "    else:\n",
    "        behavior = np.random.default_rng().normal(size=behavior.shape)\n",
    "\n",
    "    # for i in tqdm(range(behavior.shape[0])):\n",
    "        # np.save(f'{folder}/{i}.npy', behavior[i, :])\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/behavior/all'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(behavior, axis=0)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(behavior, axis=0)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(behavior, axis=0)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(behavior, axis=0)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(behavior, axis=0)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/behavior/stimulus_Frame'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(behavior, axis=0)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(behavior, axis=0)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(behavior, axis=0)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(behavior, axis=0)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(behavior, axis=0)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "logger.warning(f'Removing sessions idx = {idx_to_delete} from sessions lists.')\n",
    "session_list = np.delete(session_list, idx_to_delete, axis=0)\n",
    "sessions = np.delete(sessions, idx_to_delete, axis=0)\n",
    "\n",
    "### Load the natural images:\n",
    "# natimgdata = load_natural_images(onlyright=True)\n",
    "natimgdata = load_natural_images()\n",
    "natimgdata = natimgdata[:, natimgdata.shape[1]//2:, :]  # Only take the right half\n",
    "\n",
    "# Save natimgdata in sensorium format\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "\n",
    "    folder = f'{folder_base}/data/images'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    image_idxs = sess_obj.trialdata['ImageNumber'].values\n",
    "\n",
    "    for i, imgidx in tqdm(enumerate(image_idxs), total=len(image_idxs)):\n",
    "        file_name = f'{folder}/{i}.npy'\n",
    "        img = natimgdata[:, :, imgidx]\n",
    "        img = np.reshape(img, (-1, img.shape[0], img.shape[1]))\n",
    "        # np.save(file_name, img)  # hacky but works\n",
    "\n",
    "    print(f'num_trials for {sess[0]}/{sess[1]}: {len(image_idxs)}')\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/images/all'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(natimgdata)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(natimgdata)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(natimgdata)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(natimgdata)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(natimgdata)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/images/stimulus_Frame'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(natimgdata)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(natimgdata)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(natimgdata)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(natimgdata)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(natimgdata)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "# Save pupil center data in sensorium format\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/data/pupil_center'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "    pupil_x = sess_obj.respmat_pupilx.reshape(-1, 1)\n",
    "    pupil_y = sess_obj.respmat_pupily.reshape(-1, 1)\n",
    "\n",
    "    pupil_center = np.hstack((pupil_x, pupil_y))\n",
    "\n",
    "    if keep_behavioral_info:\n",
    "        pupil_center = replace_nan_with_avg(pupil_center)\n",
    "\n",
    "        while np.isnan(pupil_center).any():\n",
    "            pupil_center = replace_nan_with_avg(pupil_center)\n",
    "    else:\n",
    "        pupil_center = np.random.default_rng().normal(size=pupil_center.shape)\n",
    "\n",
    "    print(f'num_trials for {sess[0]}/{sess[1]}: {len(pupil_center)}')\n",
    "\n",
    "    # for i in tqdm(range(pupil_center.shape[0])):\n",
    "        # np.save(f'{folder}/{i}.npy', pupil_center[i, :])\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/pupil_center/all'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/pupil_center/stimulus_Frame'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(pupil_center, axis=0)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "# Add neuron data\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/meta/neurons'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    celldata = sess_obj.celldata.copy()\n",
    "\n",
    "    # layer\n",
    "    # V1\n",
    "    celldata.loc[(celldata['roi_name'] == 'V1') & (\n",
    "        celldata['depth'] < 250), 'layer'] = 'L2/3'\n",
    "    celldata.loc[(celldata['roi_name'] == 'V1') & (\n",
    "        celldata['depth'] >= 250) & (celldata['depth'] < 350), 'layer'] = 'L4'\n",
    "    celldata.loc[(celldata['roi_name'] == 'V1') & (\n",
    "        celldata['depth'] >= 350), 'layer'] = 'L5/6'\n",
    "\n",
    "    # PM\n",
    "    celldata.loc[(celldata['roi_name'] == 'PM') & (\n",
    "        celldata['depth'] < 250), 'layer'] = 'L2/3'\n",
    "    celldata.loc[(celldata['roi_name'] == 'PM') & (\n",
    "        celldata['depth'] >= 250) & (celldata['depth'] < 325), 'layer'] = 'L4'\n",
    "    celldata.loc[(celldata['roi_name'] == 'PM') & (\n",
    "        celldata['depth'] >= 325), 'layer'] = 'L5'\n",
    "    \n",
    "    celldata = celldata.loc[celldata['roi_name'] == area_of_interest] if area_of_interest is not None else celldata\n",
    "    \n",
    "    # Save celldata to obj\n",
    "    sess_obj.celldata = celldata.copy()\n",
    "\n",
    "    num_neurons = len(celldata)\n",
    "\n",
    "    print(f'num_neurons for {sess[0]}/{sess[1]}: {num_neurons}')\n",
    "    \n",
    "    # layer\n",
    "    # np.save(f'{folder}/layer.npy',\n",
    "    #         celldata['layer'].to_numpy(dtype='<U32'))\n",
    "    \n",
    "    # animal ids\n",
    "    # np.save(f'{folder}/animal_ids.npy',\n",
    "    #         np.full((num_neurons, ), sess_obj.animal_id, dtype='<U32'))\n",
    "\n",
    "    # area\n",
    "    # np.save(f'{folder}/area.npy',\n",
    "    #         celldata['roi_name'].to_numpy(dtype='<U32'))\n",
    "\n",
    "    # cell motor coordinates\n",
    "    # np.save(f'{folder}/cell_motor_coordinates.npy',\n",
    "    #         celldata[['xloc', 'yloc', 'depth']].to_numpy(dtype=int))\n",
    "\n",
    "    # scan idx\n",
    "    # np.save(f'{folder}/scan_idx.npy',\n",
    "    #         np.full((num_neurons, ), 0))\n",
    "\n",
    "    # sessions\n",
    "    # np.save(f'{folder}/sessions.npy',\n",
    "    #         celldata['session_id'].to_numpy(dtype='<U32'))\n",
    "\n",
    "    # unit ids\n",
    "    # np.save(f'{folder}/unit_ids.npy',\n",
    "    #         celldata['cell_id'].to_numpy(dtype='<U32'))\n",
    "\n",
    "# Save responses in sensorium format\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/data/responses'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    responses = sess_obj.respmat\n",
    "    responses = replace_nan_with_avg(responses)\n",
    "\n",
    "    celldata = sess_obj.celldata.copy()\n",
    "\n",
    "    responses = responses[celldata.index.values]\n",
    "\n",
    "    sess_obj.respmat = responses\n",
    "\n",
    "    print(f'num_neurons for {sess[0]}/{sess[1]}: {responses.shape[0]}')\n",
    "\n",
    "    # for i in tqdm(range(responses.shape[1])):\n",
    "        # np.save(f'{folder}/{i}.npy', responses[:, i])\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/responses/all'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(responses, axis=1)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(responses, axis=1)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(responses, axis=1)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(responses, axis=1)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(responses, axis=1)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "    # Meta\n",
    "    # There is also a /stimulus_Frame, but I'm not sure what the difference is\n",
    "    folder = f'{folder_base}/meta/statistics/responses/stimulus_Frame'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Mean\n",
    "    mean = np.mean(responses, axis=1)\n",
    "    # np.save(f'{folder}/mean.npy', mean)\n",
    "\n",
    "    # Std\n",
    "    std = np.std(responses, axis=1)\n",
    "    # np.save(f'{folder}/std.npy', std)\n",
    "\n",
    "    # Min\n",
    "    min = np.min(responses, axis=1)\n",
    "    # np.save(f'{folder}/min.npy', min)\n",
    "\n",
    "    # Max\n",
    "    max = np.max(responses, axis=1)\n",
    "    # np.save(f'{folder}/max.npy', max)\n",
    "\n",
    "    # Median\n",
    "    median = np.median(responses, axis=1)\n",
    "    # np.save(f'{folder}/median.npy', median)\n",
    "\n",
    "def calculate_tiers(num_images):\n",
    "    # Split into train/test/validate\n",
    "    idxs = np.arange(num_images)\n",
    "    np.random.shuffle(idxs)\n",
    "    train_idxs = idxs[:int(num_images * 0.75)]\n",
    "    test_idxs = idxs[int(num_images * 0.75):int(num_images * 0.916)]\n",
    "    validate_idxs = idxs[int(num_images * 0.916):]\n",
    "    return train_idxs, test_idxs, validate_idxs\n",
    "\n",
    "# Add trial data\n",
    "\n",
    "\n",
    "for sess, sess_obj in zip(session_list, sessions):\n",
    "    folder_base = f'{OUTPUT_FOLDER}/{sess[0]}/{sess[1]}'\n",
    "    folder = f'{folder_base}/meta/trials'\n",
    "    # os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    trial_data = sess_obj.trialdata.copy()\n",
    "    num_trials = trial_data.shape[0]\n",
    "\n",
    "    print(f'num_trials for {sess[0]}/{sess[1]}: {num_trials}')\n",
    "\n",
    "    # album\n",
    "    # ???\n",
    "    # np.save(f'{folder}/album.npy',\n",
    "    #         np.full((num_trials,), 'UNK', dtype='<U32'))\n",
    "\n",
    "    # animal id\n",
    "    # np.save(f'{folder}/animal_id.npy',\n",
    "    #         np.full((num_trials,), sess_obj.animal_id, dtype='<U32'))\n",
    "\n",
    "    # condition hash\n",
    "    # ???\n",
    "    # np.save(f'{folder}/condition_hash.npy',\n",
    "    #         np.full((num_trials,), 'UNK', dtype='<U32'))\n",
    "\n",
    "    # frame image class\n",
    "    # ???\n",
    "    # np.save(f'{folder}/frame_image_class.npy',\n",
    "    #         np.full((num_trials,), 'UNK', dtype='<U32'))\n",
    "\n",
    "    # frame image id\n",
    "    # np.save(f'{folder}/frame_image_id.npy', trial_data['ImageNumber'].values)\n",
    "\n",
    "    # frame last flip\n",
    "    # ???\n",
    "    # np.save(f'{folder}/frame_last_flip.npy',\n",
    "    #         np.full((num_trials,), 0))\n",
    "\n",
    "    # frame pre blank period\n",
    "    trial_data['tOnset'] = pd.to_datetime(trial_data['tOnset'], unit='s')\n",
    "    trial_data['tOffset'] = pd.to_datetime(trial_data['tOffset'], unit='s')\n",
    "    trial_data['presentationTime'] = trial_data['tOffset'] - \\\n",
    "        trial_data['tOnset']\n",
    "\n",
    "    # calculate inter image interval\n",
    "    trial_data['tOffset_prev'] = trial_data['tOffset'].shift(1)\n",
    "    trial_data['tIntertrial'] = trial_data['tOnset'] - \\\n",
    "        trial_data['tOffset_prev']\n",
    "    trial_data['tIntertrial'].fillna(pd.Timedelta(seconds=0.5), inplace=True)\n",
    "    trial_data['tIntertrial'] = trial_data['tIntertrial'].dt.total_seconds()\n",
    "    # np.save(f'{folder}/frame_pre_blank_period.npy',\n",
    "    #         trial_data['tIntertrial'].values)\n",
    "\n",
    "    # frame presentation time\n",
    "    # np.save(f'{folder}/frame_presentation_time.npy',\n",
    "    #         trial_data['presentationTime'].dt.total_seconds())\n",
    "\n",
    "    # frame_trial_ts\n",
    "    # np.save(f'{folder}/frame_trial_ts.npy', trial_data['tOnset'].apply(\n",
    "    #     lambda x: f\"Timestamp('{x}')\").to_numpy(dtype='<U32'))\n",
    "\n",
    "    # scan_idx\n",
    "    # ???\n",
    "    # np.save(f'{folder}/scan_idx.npy',\n",
    "    #         np.full((num_trials,), 0))\n",
    "\n",
    "    # session\n",
    "    # np.save(f'{folder}/session.npy',\n",
    "    #         np.full((num_trials,), sess_obj.session_id))\n",
    "\n",
    "    # tiers\n",
    "    trial_data['ImageCount'] = trial_data['ImageNumber'].map(\n",
    "        trial_data['ImageNumber'].value_counts())\n",
    "    trial_data['ImagePresentation'] = trial_data.groupby(\n",
    "        'ImageNumber').cumcount() + 1\n",
    "\n",
    "    # Assign tiers to images\n",
    "    for i, group in trial_data.groupby('ImageCount'):\n",
    "        for j, group2 in group.groupby('ImagePresentation'):\n",
    "            train_idxs, test_idxs, validate_idxs = calculate_tiers(\n",
    "                group2.shape[0])\n",
    "\n",
    "            # Update indices\n",
    "            train_idxs = group2.index[train_idxs]\n",
    "            test_idxs = group2.index[test_idxs]\n",
    "            validate_idxs = group2.index[validate_idxs]\n",
    "\n",
    "            # assign to tiers\n",
    "            trial_data.loc[train_idxs, 'tiers'] = 'train'\n",
    "            trial_data.loc[test_idxs, 'tiers'] = 'test'\n",
    "            trial_data.loc[validate_idxs, 'tiers'] = 'validation'\n",
    "\n",
    "    # np.save(f'{folder}/tiers.npy',\n",
    "    #         trial_data['tiers'].to_numpy(dtype='<U32'))\n",
    "\n",
    "    # trial_idx\n",
    "    # np.save(f'{folder}/trial_idx.npy', trial_data['TrialNumber'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iscell</th>\n",
       "      <th>iscell_prob</th>\n",
       "      <th>skew</th>\n",
       "      <th>radius</th>\n",
       "      <th>npix_soma</th>\n",
       "      <th>npix</th>\n",
       "      <th>xloc</th>\n",
       "      <th>...</th>\n",
       "      <th>layer</th>\n",
       "      <th>recombinase</th>\n",
       "      <th>session_id</th>\n",
       "      <th>rf_az_F</th>\n",
       "      <th>rf_el_F</th>\n",
       "      <th>rf_sz_F</th>\n",
       "      <th>rf_p_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>5.268604</td>\n",
       "      <td>6.838876</td>\n",
       "      <td>167.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L2/3</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>119.944238</td>\n",
       "      <td>34.223881</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996898</td>\n",
       "      <td>7.369462</td>\n",
       "      <td>7.338488</td>\n",
       "      <td>141.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L2/3</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>-27.602230</td>\n",
       "      <td>12.256716</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.153754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989760</td>\n",
       "      <td>3.229899</td>\n",
       "      <td>5.819851</td>\n",
       "      <td>125.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L2/3</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>43.661710</td>\n",
       "      <td>14.253731</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.088756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991979</td>\n",
       "      <td>7.171705</td>\n",
       "      <td>5.773342</td>\n",
       "      <td>117.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L2/3</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>108.903346</td>\n",
       "      <td>0.274627</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.017176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980091</td>\n",
       "      <td>7.256192</td>\n",
       "      <td>6.157345</td>\n",
       "      <td>133.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L2/3</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>123.959108</td>\n",
       "      <td>19.246269</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>0.889110</td>\n",
       "      <td>5.487384</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L4</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>71.765799</td>\n",
       "      <td>15.252239</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.015785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622431</td>\n",
       "      <td>1.244387</td>\n",
       "      <td>4.368339</td>\n",
       "      <td>64.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L4</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>80.799257</td>\n",
       "      <td>20.244776</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.024745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684631</td>\n",
       "      <td>1.711489</td>\n",
       "      <td>6.102885</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L4</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>83.810409</td>\n",
       "      <td>12.256716</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.083206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976950</td>\n",
       "      <td>2.105739</td>\n",
       "      <td>6.052476</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L4</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>45.669145</td>\n",
       "      <td>18.247761</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.231020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951370</td>\n",
       "      <td>1.061183</td>\n",
       "      <td>4.612396</td>\n",
       "      <td>71.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>L4</td>\n",
       "      <td>non</td>\n",
       "      <td>LPE10885_2023_10_20</td>\n",
       "      <td>112.918216</td>\n",
       "      <td>34.223881</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1173 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iscell  iscell_prob      skew    radius  npix_soma   npix   xloc  ...  layer  recombinase           session_id     rf_az_F    rf_el_F  rf_sz_F    rf_p_F\n",
       "0        1.0     0.967153  5.268604  6.838876      167.0  383.0  254.0  ...   L2/3          non  LPE10885_2023_10_20  119.944238  34.223881     28.0  0.001149\n",
       "1        1.0     0.996898  7.369462  7.338488      141.0  190.0  406.0  ...   L2/3          non  LPE10885_2023_10_20  -27.602230  12.256716     17.0  0.153754\n",
       "2        1.0     0.989760  3.229899  5.819851      125.0  150.0  490.0  ...   L2/3          non  LPE10885_2023_10_20   43.661710  14.253731     33.0  0.088756\n",
       "3        1.0     0.991979  7.171705  5.773342      117.0  145.0  210.0  ...   L2/3          non  LPE10885_2023_10_20  108.903346   0.274627      6.0  0.017176\n",
       "4        1.0     0.980091  7.256192  6.157345      133.0  176.0  262.0  ...   L2/3          non  LPE10885_2023_10_20  123.959108  19.246269    169.0  0.000006\n",
       "...      ...          ...       ...       ...        ...    ...    ...  ...    ...          ...                  ...         ...        ...      ...       ...\n",
       "1168     1.0     0.920875  0.889110  5.487384       79.0   93.0  465.0  ...     L4          non  LPE10885_2023_10_20   71.765799  15.252239      2.0  0.015785\n",
       "1169     1.0     0.622431  1.244387  4.368339       64.0   79.0  139.0  ...     L4          non  LPE10885_2023_10_20   80.799257  20.244776      8.0  0.024745\n",
       "1170     1.0     0.684631  1.711489  6.102885       70.0   77.0  201.0  ...     L4          non  LPE10885_2023_10_20   83.810409  12.256716      3.0  0.083206\n",
       "1171     1.0     0.976950  2.105739  6.052476       79.0   93.0  493.0  ...     L4          non  LPE10885_2023_10_20   45.669145  18.247761     16.0  0.231020\n",
       "1172     1.0     0.951370  1.061183  4.612396       71.0   82.0   23.0  ...     L4          non  LPE10885_2023_10_20  112.918216  34.223881    115.0  0.000083\n",
       "\n",
       "[1173 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_neurons for LPE09665/2023_03_20: 563\n",
    "num_neurons for LPE10883/2023_10_23: 854\n",
    "num_neurons for LPE10883/2023_10_31: 1157\n",
    "num_neurons for LPE10884/2023_10_12: 1071\n",
    "num_neurons for LPE10885/2023_10_20: 1173\n",
    "num_neurons for LPE10919/2023_11_09: 1735\n",
    "num_neurons for LPE11086/2023_12_16: 903\n",
    "num_neurons for LPE11086/2024_01_09: 1134\n",
    "num_neurons for LPE11495/2024_02_29: 1007\n",
    "num_neurons for LPE11998/2024_05_08: 570\n",
    "num_neurons for LPE12223/2024_06_11: 1214\n",
    "num_neurons for LPE09665/2023_03_20: 563\n",
    "num_neurons for LPE10883/2023_10_23: 854\n",
    "num_neurons for LPE10883/2023_10_31: 1157\n",
    "num_neurons for LPE10884/2023_10_12: 1071\n",
    "num_neurons for LPE10885/2023_10_20: 1173\n",
    "num_neurons for LPE10919/2023_11_09: 1735\n",
    "num_neurons for LPE11086/2023_12_16: 903\n",
    "num_neurons for LPE11086/2024_01_09: 1134\n",
    "num_neurons for LPE11495/2024_02_29: 1007\n",
    "num_neurons for LPE11998/2024_05_08: 570\n",
    "num_neurons for LPE12223/2024_06_11: 1214\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
